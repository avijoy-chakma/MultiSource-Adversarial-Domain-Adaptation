{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import tqdm\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import network as net\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Torso_dataset = []\n",
    "RA_dataset = []\n",
    "LA_dataset = []\n",
    "RL_dataset = []\n",
    "LL_dataset = []\n",
    "Torso_gt = []\n",
    "RA_gt = []\n",
    "LA_gt = []\n",
    "RL_gt = []\n",
    "LL_gt = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the save_path field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/avijoychakma/Downloads/DSADS Files/\"\n",
    "position = [\"Torso\",\"RA\",\"LA\",\"RL\",\"LL\"]\n",
    "win_size=128\n",
    "step_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for position_index in range(1,6): #Back, RUA, RLA, LUA, LLA\n",
    "    for person_index in range(1,9): # 4 Persons\n",
    "        file_name = \"U\"+str(person_index) + \"_\"+position[position_index-1]\n",
    "        \n",
    "        df = pd.read_csv(save_path+file_name+'.csv', sep=\",\")   \n",
    "        len_df = df.shape[0]\n",
    "        narray = df.to_numpy()\n",
    "\n",
    "        for i in range(0, len_df, step_size):\n",
    "            window = narray[i:i+win_size,0:9]\n",
    "            \n",
    "            if window.shape[0] != win_size:\n",
    "                continue\n",
    "            else:\n",
    "                reshaped_window = window.reshape(1,win_size,1,9)\n",
    "                gt = np.bincount(narray[i:i+win_size,10:11].astype(int).ravel()).argmax()\n",
    "                \n",
    "                if position_index == 1:\n",
    "                    Torso_dataset.append(reshaped_window)\n",
    "                    Torso_gt.append(gt)\n",
    "                elif position_index == 2:\n",
    "                    RA_dataset.append(reshaped_window)\n",
    "                    RA_gt.append(gt)\n",
    "                elif position_index == 3:\n",
    "                    LA_dataset.append(reshaped_window)\n",
    "                    LA_gt.append(gt)\n",
    "                elif position_index == 4:\n",
    "                    RL_dataset.append(reshaped_window)\n",
    "                    RL_gt.append(gt)\n",
    "                elif position_index == 5:\n",
    "                    LL_dataset.append(reshaped_window)\n",
    "                    LL_gt.append(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    data = np.loadtxt('result.csv', delimiter=',')\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(data[:, 0]) + 1), data[:, 0], color='blue', label='train')\n",
    "    plt.plot(range(1, len(data[:, 1]) + 1), data[:, 1], color='red', label='test')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch', fontsize=14)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "    plt.title('Training and Test Accuracy', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Torso_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Torso = np.concatenate( Torso_dataset, axis=0 )\n",
    "Torso_Ground_Truth = np.array( Torso_gt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9360, 128, 1, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Torso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_label(y_onehot):\n",
    "    a = np.argwhere(y_onehot == 1)\n",
    "    return a[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the train-test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Torso, Torso_Ground_Truth, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = onehot_to_label(np.eye(7)[y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = onehot_to_label(np.eye(7)[y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7020, 128, 1, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =X_train.astype(np.float32)\n",
    "y_train =y_train.astype(np.float32)\n",
    "X_test =X_test.astype(np.float32)\n",
    "y_test =y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7020, 128, 1, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader(Dataset):\n",
    "    def __init__(self, samples, labels, transform=None):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         return self.transform(self.samples[index]), self.transform(self.samples[index])\n",
    "        return self.samples[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loader Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(batch_size=64):\n",
    "  \n",
    "    X_train_swap = np.swapaxes(X_train,1,3)\n",
    "    X_test_swap = np.swapaxes(X_test,1,3)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0,0,0,0,0,0,0,0,0), std=(1,1,1,1,1,1,1,1,1))\n",
    "    ])\n",
    "    \n",
    "#     train_set = data_loader(X_train_swap, y_train, transform)\n",
    "#     test_set = data_loader(X_test_swap, y_test, transform)\n",
    "\n",
    "    train_set = data_loader(X_train_swap, y_train)\n",
    "    test_set = data_loader(X_test_swap, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Train Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_EPOCH = 5\n",
    "LEARNING_RATE = 0.01\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "result = []\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_loader, test_loader):\n",
    "    n_batch = len(train_loader.dataset) // BATCH_SIZE\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for e in range(N_EPOCH):\n",
    "        model.train()\n",
    "        correct, total_loss = 0, 0\n",
    "        total = 0\n",
    "        for index, (sample, target) in enumerate(train_loader):\n",
    "            sample, target = sample.to(DEVICE).float(), target.to(DEVICE).long()        \n",
    "            sample = sample.view(-1, 9, 1, 128)\n",
    "            output = model(sample)\n",
    "            loss = criterion(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum()\n",
    "\n",
    "            if index % 20 == 0:\n",
    "                tqdm.tqdm.write('Epoch: [{}/{}], Batch: [{}/{}], loss:{:.4f}'.format(e + 1, N_EPOCH, index + 1, n_batch,\n",
    "                                                                                     loss.item()))\n",
    "        acc_train = float(correct) * 100.0 / (BATCH_SIZE * n_batch)\n",
    "        tqdm.tqdm.write(\n",
    "            'Epoch: [{}/{}], loss: {:.4f}, train acc: {:.2f}%'.format(e + 1, N_EPOCH, total_loss * 1.0 / n_batch,\n",
    "                                                                      acc_train))\n",
    "\n",
    "        # Testing\n",
    "        model.train(False)\n",
    "        with torch.no_grad():\n",
    "            correct, total = 0, 0\n",
    "            for sample, target in test_loader:\n",
    "                sample, target = sample.to(DEVICE).float(), target.to(DEVICE).long()\n",
    "                sample = sample.view(-1, 9, 1, 128)\n",
    "                output = model(sample)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum()\n",
    "        acc_test = float(correct) * 100 / total\n",
    "        tqdm.tqdm.write('Epoch: [{}/{}], test acc: {:.2f}%'.format(e + 1, N_EPOCH, float(correct) * 100 / total))\n",
    "        result.append([acc_train, acc_test])\n",
    "        result_np = np.array(result, dtype=float)\n",
    "        np.savetxt('result.csv', result_np, fmt='%.2f', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"/home/avijoychakma/Downloads/DSADS Files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/80], Batch: [1/109], loss:1.9444\n",
      "Epoch: [1/80], Batch: [21/109], loss:1.9324\n",
      "Epoch: [1/80], Batch: [41/109], loss:1.8895\n",
      "Epoch: [1/80], Batch: [61/109], loss:1.6546\n",
      "Epoch: [1/80], Batch: [81/109], loss:1.6209\n",
      "Epoch: [1/80], Batch: [101/109], loss:1.6017\n",
      "Epoch: [1/80], loss: 1.7625, train acc: 41.14%\n",
      "Epoch: [1/80], test acc: 50.38%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-deca2ae727d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.2f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-7f3b685d4cf6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: [{}/{}], test acc: {:.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mresult_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.2f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(10)\n",
    "    model = net.Network().to(DEVICE)\n",
    "    train_loader, test_loader = load()\n",
    "    optimizer = optim.SGD(params=model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    \n",
    "    train(model, optimizer, train_loader, test_loader)\n",
    "    result = np.array(result, dtype=float)\n",
    "    np.savetxt('result.csv', result, fmt='%.2f', delimiter=',')\n",
    "    \n",
    "    # Print model's state_dict\n",
    "    print(\"Model's state_dict:\")\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "#     # Print optimizer's state_dict\n",
    "#     print(\"Optimizer's state_dict:\")\n",
    "#     for var_name in optimizer.state_dict():\n",
    "#         print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "    \n",
    "    plot()\n",
    "    \n",
    "    torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
