{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import tqdm\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "RANDOM_SEED = 42\n",
    "import torch.nn as nn\n",
    "from matplotlib.lines import Line2D   \n",
    "import time\n",
    "import DataPreprocess\n",
    "from Model import AccExtractor, AccClassifier, AccDiscriminator\n",
    "from Model import get_cls_loss, get_dis_loss, get_confusion_loss\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='app.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/avijoychakma/Downloads/DTCN-AR/Dataset Preprocessing/PAMAP/ACC-Positionwise-Normalization/Data Files-4 Activities/\"\n",
    "pth_path = \"/home/avijoychakma/Downloads/DTCN-AR/Dataset Preprocessing/PAMAP/ACC-Positionwise-Normalization/Trained-Model-4 Activities/\"\n",
    "# snapshot = \"/home/avijoychakma/Downloads/DTCN-AR/Dataset Preprocessing/PAMAP/ACC-Positionwise-Normalization/Trained-Model-7 Activities/Snapshot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_one = 1\n",
    "source_two = 3\n",
    "selected_Target = 2\n",
    "selected_user = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 250\n",
    "gan_epoches=2\n",
    "cls_epoches=6\n",
    "batch_size = 32\n",
    "plot_interval = 100\n",
    "EPSILON = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "max_correct = 0\n",
    "max_step = 0\n",
    "max_epoch = 0\n",
    "gpu_id = 0\n",
    "lr=0.00001\n",
    "beta1=0.9\n",
    "beta2=0.999\n",
    "log_interval = 24\n",
    "threshold=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dominant_Arm_train = []\n",
    "Torso_train = []\n",
    "Dominant_Leg_train = []\n",
    "\n",
    "Dominant_Arm_gt_train = []\n",
    "Torso_gt_train = []\n",
    "Dominant_Leg_gt_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dominant_Arm_valid = []\n",
    "Torso_valid = []\n",
    "Dominant_Leg_valid = []\n",
    "\n",
    "Dominant_Arm_gt_valid = []\n",
    "Torso_gt_valid = []\n",
    "Dominant_Leg_gt_valid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size=128\n",
    "overlap = 0.5\n",
    "step_size=int(win_size * overlap)\n",
    "AXIS = 3\n",
    "FROM = 0\n",
    "TO = FROM+3\n",
    "START = 4\n",
    "END = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = [\"train\",\"valid\"]\n",
    "user = [\"User1\",\"User2\",\"User3\",\"User4\",\"User5\",\"User6\",\"User7\",\"User8\"]\n",
    "position = ['Dominant_Arm', 'Torso', 'Dominant_Leg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in the preprocessing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User3_Dominant_Arm_train\n",
      "User3_Dominant_Arm_valid\n",
      "User3_Torso_train\n",
      "User3_Torso_valid\n",
      "User3_Dominant_Leg_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 3/3 [00:00<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User3_Dominant_Leg_valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for position_index in tqdm.tqdm(range(0,3)): #'Dominant_Arm', 'Torso', 'Dominant_Leg'\n",
    "    for split_index in range(0,2):\n",
    "        file_name = user[selected_user-1] + \"_\" + position[position_index]+'_'+item[split_index]\n",
    "        \n",
    "        print(file_name)\n",
    "        df = pd.read_csv(save_path+file_name+'.csv', sep=\",\")   \n",
    "        len_df = df.shape[0]\n",
    "        narray = df.to_numpy()\n",
    "\n",
    "        for i in range(0, len_df, step_size):\n",
    "            window = narray[i:i+win_size, FROM:TO]\n",
    "            \n",
    "            if window.shape[0] != win_size:\n",
    "                continue\n",
    "            else:\n",
    "                reshaped_window = window.reshape(1,win_size,1,AXIS)\n",
    "                gt = np.bincount(narray[i:i+win_size,START:END].astype(int).ravel()).argmax()\n",
    "                \n",
    "                if position_index == 0:\n",
    "                    if split_index == 0:\n",
    "                        Dominant_Arm_train.append(reshaped_window)\n",
    "                        Dominant_Arm_gt_train.append(gt)\n",
    "                    elif split_index == 1:\n",
    "                        Dominant_Arm_valid.append(reshaped_window)\n",
    "                        Dominant_Arm_gt_valid.append(gt)\n",
    "                elif position_index == 1:\n",
    "                    if split_index == 0:\n",
    "                        Torso_train.append(reshaped_window)\n",
    "                        Torso_gt_train.append(gt)\n",
    "                    elif split_index == 1:\n",
    "                        Torso_valid.append(reshaped_window)\n",
    "                        Torso_gt_valid.append(gt)\n",
    "                elif position_index == 2:\n",
    "                    if split_index == 0:\n",
    "                        Dominant_Leg_train.append(reshaped_window)\n",
    "                        Dominant_Leg_gt_train.append(gt)\n",
    "                    elif split_index == 1:\n",
    "                        Dominant_Leg_valid.append(reshaped_window)\n",
    "                        Dominant_Leg_gt_valid.append(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_parameters(classifier_A, classifier_B = 'none'):\n",
    "    for name, param in classifier_A.named_parameters():\n",
    "        logging.warning(\"Name: {}\".format(name))\n",
    "        logging.warning(\"Param: {}\".format(param.dtype))\n",
    "\n",
    "    if not (classifier_B is None):\n",
    "        for name in classifier_B.named_parameters():\n",
    "            logging.warning(\"Name: {}\".format(name))\n",
    "            logging.warning(\"Param: {}\".format(param.dtype))\n",
    "            \n",
    "def similarity_between_model_layers(model_A, model_B):        \n",
    "    model_A_param_list= []\n",
    "    model_A_param_layers_no = len(list(model_A.parameters()))\n",
    "    for x in range(model_A_param_layers_no):\n",
    "        a = list(model_A.parameters())[x].clone()\n",
    "        model_A_param_list.append(a)\n",
    "\n",
    "    model_B_param_list= []\n",
    "    model_B_param_layers_no = len(list(model_B.parameters()))\n",
    "    for x in range(model_B_param_layers_no):\n",
    "        a = list(model_B.parameters())[x].clone()\n",
    "        model_B_param_list.append(a) \n",
    "\n",
    "    for x in range(model_B_param_layers_no):\n",
    "        logging.warning(\"Classifier A and Classifier B have Same Parameter in Layer {}:{}\".format(x,torch.equal(model_A_param_list[x].data,model_B_param_list[x].data)))\n",
    "        \n",
    "def update_checking_between_model():\n",
    "    # Needs to modify the function - \"similarity_between_model_layers\"\n",
    "    for x in range(10):\n",
    "        b = list(extractor.parameters())[x].clone()\n",
    "        logging.warning(\"Adversarial Iteration: {}, At Extractor Layer: {}, Same Parameter:{}\".format(gan_epoch,x,torch.equal(param_list[x].data, b.data)))\n",
    "\n",
    "    for x in range(A_param_layers_no):\n",
    "        b = list(discriminator_A.parameters())[x].clone()\n",
    "        logging.warning(\"Adversarial Iteration: {}, At Discriminator-A Layer: {}, Same Parameter:{}\".format(gan_epoch,x,torch.equal(discrim_A_param_list[x].data, b.data)))\n",
    "\n",
    "    for x in range(B_param_layers_no):\n",
    "        b = list(discriminator_B.parameters())[x].clone()\n",
    "        logging.warning(\"Adversarial Iteration: {}, At Discriminator-B Layer: {}, Same Parameter:{}\".format(gan_epoch,x,torch.equal(discrim_B_param_list[x].data, b.data)))\n",
    "\n",
    "        \n",
    "def ones_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1)).cuda(gpu_id)\n",
    "    return data\n",
    "\n",
    "\n",
    "def zeros_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1)).cuda(gpu_id)\n",
    "    return data\n",
    "\n",
    "def BCELossCalculation(source, source_no):\n",
    "    length = len(source)\n",
    "    t_length= len(target)\n",
    "\n",
    "    logging.warning(\"S1 length: %d, Target length: %d\",length, t_length)\n",
    "    \n",
    "    if source_no == 1:\n",
    "        s1_error_fake = loss(s1_source, ones_target(length))\n",
    "        s1_error_real = loss(s1_target, zeros_target(t_length))\n",
    "        s1_t_dis_loss = s1_error_fake + s1_error_real\n",
    "        logging.warning(\"S1 Disc loss: %s\", s1_t_dis_loss.data)\n",
    "        return s1_t_dis_loss\n",
    "    else:\n",
    "        s2_error_fake = loss(s2_source, ones_target(length))\n",
    "        s2_error_real = loss(s2_target, zeros_target(t_length))\n",
    "        s2_t_dis_loss = s2_error_fake + s2_error_real\n",
    "        logging.warning(\"S2 Disc Loss: %s\", s2_t_dis_loss.data)\n",
    "        return s2_t_dis_loss\n",
    "\n",
    "def check_a_sample(sample, sample_target):\n",
    "    predicted_label = F.log_softmax(sample[0], dim = 0)\n",
    "    logging.warning(\"Item list: %s\",sample[0])\n",
    "    logging.warning(\"Predicted: %s\", predicted_label)\n",
    "\n",
    "    logging.warning(\"Sum: %.12f\", sum(predicted_label))\n",
    "    logging.warning(\"Max: %.12f\", max(predicted_label))\n",
    "\n",
    "    logging.warning(\"Target: %s\", sample_target[0])\n",
    "\n",
    "\n",
    "def plot_grad_flow(named_parameters, step, gan_epoch, batch):\n",
    "    #             if (i+1) % plot_interval == 0:\n",
    "#                 plot_grad_flow(discriminator_A.named_parameters(), step, gan_epoch, batch_size)\n",
    "\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "            \n",
    "    plt.figure()\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.5, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.5, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=0.08) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    string = \"At Step \"+str(step)+\", Gan epoch: \"+str(gan_epoch)+ \", batch: \"+str(batch)\n",
    "    plt.title(\"Gradient flow\"+string)\n",
    "    plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "    \n",
    "def dataset_labelling():\n",
    "    print(\"Sitting = 0\")\n",
    "    print(\"Standing = 1\")\n",
    "    print(\"Lying = 2\")\n",
    "    print(\"Walking = 3\")\n",
    "    print(\"Running = 4\")\n",
    "    print(\"Ascending up = 5\")\n",
    "    print(\"Descending Down = 6\")\n",
    "    \n",
    "def plot_activity(activity, df, position, i=1000):\n",
    "    data = df[df['Activity'] == activity][['AccX', 'AccY','AccZ', 'GyrX', 'GyrY', 'GyrZ', 'MagX', 'MagY','MagZ']][:i]\n",
    "    title_name = \"\"\n",
    "    if position == 0:\n",
    "        title_name = \"Torso\"\n",
    "    elif position == 1:\n",
    "        title_name = \"Right Arm\"\n",
    "    elif position == 2:\n",
    "        title_name = \"Left Arm\"\n",
    "    elif position == 3:\n",
    "        title_name = \"Right Leg\"\n",
    "    elif position == 4:\n",
    "        title_name = \"Left Leg\"\n",
    "        \n",
    "    axis = data.plot(subplots=True, figsize=(16, 12), title=title_name)\n",
    "    for ax in axis:\n",
    "        ax.legend(loc='lower left', bbox_to_anchor=(1.0, 0.5))\n",
    "        \n",
    "def plot_datasets(df, activity_id, pos, i=500):\n",
    "    plot_activity(activity_id, df, pos, i)\n",
    "    \n",
    "def training_plot(x_value, y_value):\n",
    "    plt.figure()\n",
    "    plt.plot(np.asarray(x_value), np.asarray(y_value), color='blue', label='Accuracy')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch', fontsize=14)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "    \n",
    "    result = np.where(y_value == np.amax(y_value))\n",
    "    plt.title('Max Accuracy:'+str(np.max(np.asarray(y_value))) + 'at '+ str(result[0]), fontsize=20)\n",
    "    \n",
    "def plot_data_distribution(s1, s2, target, activity_list):\n",
    "\n",
    "    n_groups = len(activity_list)\n",
    "\n",
    "    # create plot\n",
    "    #fig, ax = plt.subplots()\n",
    "    plt.figure(figsize=(12,8))\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.25\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, s1, bar_width, alpha=opacity, color='b', label='Source1')\n",
    "    rects2 = plt.bar(index + bar_width, s2, bar_width, alpha=opacity, color='g', label='Source2')\n",
    "    rects3 = plt.bar(index + 2*bar_width, target, bar_width, alpha=opacity, color='m',label='Target')\n",
    "\n",
    "    plt.xlabel('Activity')\n",
    "    plt.ylabel('Window Number')\n",
    "    plt.title('Window Distribution')\n",
    "    plt.xticks(index + bar_width, activity_list, rotation = 45)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#     Citiation: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import numpy as np\n",
    "   \n",
    "def plot_confusion_matrix(cm,target_names,cmap=None,normalize=True,title='Confusion matrix'):\n",
    "\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=70)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    print(thresh)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     verticalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy*100, misclass*100))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data loaders\n",
    "    - Datasets are converted into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source_one == 1:\n",
    "    S1 = np.concatenate( Dominant_Arm_train, axis=0 )\n",
    "    S1_GT = np.array(Dominant_Arm_gt_train  )\n",
    "    S1_Test = np.concatenate( Dominant_Arm_valid, axis=0 )\n",
    "    S1_Test_GT = np.array(Dominant_Arm_gt_valid  )\n",
    "elif source_one == 2:\n",
    "    S1 = np.concatenate( Torso_train, axis=0 )\n",
    "    S1_GT = np.array(Torso_gt_train  )\n",
    "    S1_Test = np.concatenate(Torso_valid, axis=0)\n",
    "    S1_Test_GT = np.array(Torso_gt_valid)\n",
    "elif source_one == 3:\n",
    "    S1 = np.concatenate( Dominant_Leg_train, axis=0 )\n",
    "    S1_GT = np.array(Dominant_Leg_gt_train  )\n",
    "    S1_Test = np.concatenate( Dominant_Leg_valid, axis=0 )\n",
    "    S1_Test_GT = np.array(Dominant_Leg_gt_valid  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source_two == 1:\n",
    "    S2 = np.concatenate( Dominant_Arm_train, axis=0 )\n",
    "    S2_GT = np.array(Dominant_Arm_gt_train  )\n",
    "    S2_Test = np.concatenate( Dominant_Arm_valid, axis=0 )\n",
    "    S2_Test_GT = np.array(Dominant_Arm_gt_valid  )\n",
    "elif source_two == 2:\n",
    "    S2 = np.concatenate( Torso_train, axis=0 )\n",
    "    S2_GT = np.array(Torso_gt_train  )\n",
    "    S2_Test = np.concatenate(Torso_valid, axis=0)\n",
    "    S2_Test_GT = np.array(Torso_gt_valid)\n",
    "elif source_two == 3:\n",
    "    S2 = np.concatenate( Dominant_Leg_train, axis=0 )\n",
    "    S2_GT = np.array(Dominant_Leg_gt_train  )\n",
    "    S2_Test = np.concatenate( Dominant_Leg_valid, axis=0 )\n",
    "    S2_Test_GT = np.array(Dominant_Leg_gt_valid  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_Target == 1:\n",
    "    Target = np.concatenate( Dominant_Arm_train, axis=0 )\n",
    "    Target_GT = np.array(Dominant_Arm_gt_train)\n",
    "elif selected_Target == 2:\n",
    "    Target = np.concatenate(Torso_train, axis=0)\n",
    "    Target_GT = np.array(Torso_gt_train)\n",
    "elif selected_Target == 3:\n",
    "    Target = np.concatenate( Dominant_Leg_train, axis=0 )\n",
    "    Target_GT = np.array(Dominant_Leg_gt_train  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(S1_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(S2_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Target_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Target_Sample = len(Target_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_gt_number = len(np.unique(S1_GT))\n",
    "output_gt_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "source1_Ground_Truth = DataPreprocess.onehot_to_label(np.eye(output_gt_number)[S1_GT])\n",
    "source2_Ground_Truth = DataPreprocess.onehot_to_label(np.eye(output_gt_number)[S2_GT])\n",
    "target_Ground_Truth = DataPreprocess.onehot_to_label(np.eye(output_gt_number)[Target_GT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(Target_GT, return_counts=True)\n",
    "target_dict = dict(zip(unique, counts))\n",
    "target_samples = np.fromiter(target_dict.values(), dtype=float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(S1_GT, return_counts=True)\n",
    "s1_dict = dict(zip(unique, counts))\n",
    "s1_samples = np.fromiter(s1_dict.values(), dtype=float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(S2_GT, return_counts=True)\n",
    "s2_dict = dict(zip(unique, counts))\n",
    "s2_samples = np.fromiter(s2_dict.values(), dtype=float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = ['Sitting', 'Standing', 'Lying', 'Walking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_distribution(s1_samples, s2_samples, target_samples, activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source1_set =S1.astype(np.float32)\n",
    "source1_Ground_Truth =source1_Ground_Truth.astype(np.float32)\n",
    "source2_set =S2.astype(np.float32)\n",
    "source2_Ground_Truth =source2_Ground_Truth.astype(np.float32)\n",
    "target_set =Target.astype(np.float32)\n",
    "target_Ground_Truth =target_Ground_Truth.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source1_loader = DataPreprocess.load(source1_set, source1_Ground_Truth)\n",
    "source2_loader = DataPreprocess.load(source2_set, source2_Ground_Truth)\n",
    "target_loader = DataPreprocess.load(target_set, target_Ground_Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = AccExtractor().to(DEVICE)\n",
    "classifier_A = AccClassifier(output_gt_number).to(DEVICE)\n",
    "classifier_B = AccClassifier(output_gt_number).to(DEVICE)\n",
    "\n",
    "discriminator_A = AccDiscriminator().to(DEVICE)\n",
    "discriminator_B = AccDiscriminator().to(DEVICE)\n",
    "\n",
    "extractor.load_state_dict(torch.load(pth_path + \"extractor.pth\"))\n",
    "classifier_A.load_state_dict(torch.load(pth_path + \"classifierA.pth\"))\n",
    "classifier_B.load_state_dict(torch.load(pth_path + \"classifierB.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_extract = optim.Adam(extractor.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optim_s1_t_dis = optim.Adam(discriminator_A.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optim_s2_t_dis = optim.Adam(discriminator_B.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optim_s1_cls = optim.Adam(classifier_A.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optim_s2_cls = optim.Adam(classifier_B.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "loss = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "calculate_softmax = nn.Softmax()\n",
    "\n",
    "x_value = []\n",
    "y_value = []\n",
    "\n",
    "for step in tqdm.tqdm(range(steps)):\n",
    "\n",
    "    print(\"Step: {} #### Part1: Multi-way Adversarial Adaptation\".format(step))\n",
    "\n",
    "    # Features fed into the classifiers and domain discriminators. # C fixed, F and D are updated\n",
    "    extractor.train()\n",
    "    discriminator_A.train()\n",
    "    discriminator_B.train()\n",
    "    classifier_A.eval()\n",
    "    classifier_B.eval()  \n",
    "\n",
    "    # For two sources, two weighted losses\n",
    "    s1_weight_loss = 0\n",
    "    s2_weight_loss = 0\n",
    "    alpha_S1 = 0\n",
    "    alpha_S2 = 0\n",
    "    \n",
    "    # GAN-Epoch corresponds to beta in Algo-2, line-4\n",
    "    for gan_epoch in range(gan_epoches):\n",
    "\n",
    "        # [Online Hard Domain Batch Mining]\n",
    "        s1_loader, s2_loader, t_loader = iter(source1_loader), iter(source2_loader), iter(target_loader)\n",
    "        for i, (t_sample, t_labels) in tqdm.tqdm(enumerate(t_loader)):\n",
    "            try:\n",
    "                s1_sample, s1_labels = s1_loader.next()\n",
    "            except StopIteration:\n",
    "                s1_loader = iter(source1_loader)\n",
    "                s1_sample, s1_labels = s1_loader.next()\n",
    "            try:\n",
    "                s2_sample, s2_labels = s2_loader.next()\n",
    "            except StopIteration:\n",
    "                s2_loader = iter(source2_loader)\n",
    "                s2_sample, s2_labels = s2_loader.next()\n",
    "\n",
    "            s1_sample, s1_labels = Variable(s1_sample.cuda(gpu_id)), Variable(s1_labels.cuda(gpu_id))\n",
    "            s2_sample, s2_labels = Variable(s2_sample.cuda(gpu_id)), Variable(s2_labels.cuda(gpu_id))\n",
    "            t_sample = Variable(t_sample.cuda(gpu_id))\n",
    "            \n",
    "            extractor.zero_grad()\n",
    "\n",
    "            s1_feature = extractor(s1_sample)\n",
    "            s2_feature = extractor(s2_sample)\n",
    "            t_feature = extractor(t_sample)\n",
    "            \n",
    "            # Classification loss. Second part of the Equation-4\n",
    "            s1_cls = classifier_A(s1_feature)\n",
    "            s2_cls = classifier_B(s2_feature)      \n",
    "            \n",
    "            s1_labels = s1_labels.long()\n",
    "            s2_labels = s2_labels.long()\n",
    "            \n",
    "            s1_cls_loss = get_cls_loss(s1_cls, s1_labels)\n",
    "            s2_cls_loss = get_cls_loss(s2_cls, s2_labels)\n",
    "\n",
    "            # For discriminator1 loss calculation\n",
    "            s1_source = discriminator_A(s1_feature)+ EPSILON\n",
    "            s1_target = discriminator_A(t_feature)+ EPSILON\n",
    "            \n",
    "            # For discriminator2 loss calculation\n",
    "            s2_source = discriminator_B(s2_feature) + EPSILON\n",
    "            s2_target = discriminator_B(t_feature) + EPSILON\n",
    "            \n",
    "            # Calculate discripency losses\n",
    "            s1_t_dis_loss = get_dis_loss(s1_source, s1_target)\n",
    "            s2_t_dis_loss = get_dis_loss(s2_source, s2_target)\n",
    "            \n",
    "\n",
    "            # Calculate Confusion loss\n",
    "            s1_ori_log = torch.log(s1_source)\n",
    "            s1_sub_log = torch.log(1-s1_source)\n",
    "            s1_ori_log_mean = torch.mean(s1_ori_log) \n",
    "            s1_sub_log_mean = torch.mean(s1_sub_log)\n",
    "            s1_s_conf_loss = s1_ori_log_mean + s1_sub_log_mean\n",
    "            \n",
    "            s2_ori_log = torch.log(s2_source)\n",
    "            s2_sub_log = torch.log(1-s2_source)\n",
    "            s2_ori_log_mean = torch.mean(s2_ori_log)\n",
    "            s2_sub_log_mean = torch.mean(s2_sub_log)\n",
    "            s2_s_conf_loss = s2_ori_log_mean + s2_sub_log_mean\n",
    "            \n",
    "            s1_tar_ori_log = torch.log(s1_target)\n",
    "            s1_tar_sub_log = torch.log(1-s1_target)\n",
    "            s1_tar_ori_log_mean = torch.mean(s1_tar_ori_log)\n",
    "            s1_tar_sub_log_mean = torch.mean(s1_tar_sub_log)\n",
    "            s1_tar_conf_loss = s1_tar_ori_log_mean + s1_tar_sub_log_mean\n",
    "            \n",
    "            s2_tar_ori_log = torch.log(s2_target)\n",
    "            s2_tar_sub_log = torch.log(1-s2_target)\n",
    "            s2_tar_ori_log_mean = torch.mean(s2_tar_ori_log)\n",
    "            s2_tar_sub_log_mean = torch.mean(s2_tar_sub_log)\n",
    "            s2_tar_conf_loss = s2_tar_ori_log_mean + s2_tar_sub_log_mean\n",
    "        \n",
    "            # Perplexity Score\n",
    "            s1_weight_loss += -s1_tar_sub_log_mean.data\n",
    "            s2_weight_loss += -s2_tar_sub_log_mean.data\n",
    "            \n",
    "            alpha_S1 +=  (alpha_S1 * i*gan_epoch  + torch.mean(s1_source) )/(i*gan_epoch+1)\n",
    "            alpha_S2 +=  (alpha_S2 * i*gan_epoch  + torch.mean(s2_source) )/(i*gan_epoch+1)\n",
    "            \n",
    "            s1_t_confusion_loss = -(0.5 * s1_s_conf_loss + 0.5 * s1_tar_conf_loss)\n",
    "            s2_t_confusion_loss = -(0.5 * s2_s_conf_loss + 0.5 * s2_tar_conf_loss)\n",
    "            \n",
    "            if s1_t_dis_loss.data >= s2_t_dis_loss.data:\n",
    "                SELECTIVE_SOURCE = \"S1\"\n",
    "                torch.autograd.backward([s1_cls_loss, s2_cls_loss, s1_t_confusion_loss])\n",
    "            else:\n",
    "                SELECTIVE_SOURCE = \"S2\"\n",
    "                torch.autograd.backward([s1_cls_loss, s2_cls_loss, s2_t_confusion_loss])\n",
    "                \n",
    "                \n",
    "            optim_extract.step()\n",
    "            discriminator_A.zero_grad()\n",
    "            discriminator_B.zero_grad()\n",
    "\n",
    "            # Detach features so that it does not update the feature extractor.\n",
    "            # Only update the discriminators\n",
    "            s1_source = discriminator_A(s1_feature.detach())\n",
    "            s1_target = discriminator_A(t_feature.detach())\n",
    "            s2_source = discriminator_B(s2_feature.detach())\n",
    "            s2_target = discriminator_B(t_feature.detach())\n",
    "\n",
    "            # Update D\n",
    "            s1_t_dis_loss = get_dis_loss(s1_source, s1_target)\n",
    "            s2_t_dis_loss = get_dis_loss(s2_source, s2_target)\n",
    "            torch.autograd.backward([s1_t_dis_loss, s2_t_dis_loss])\n",
    "\n",
    "            optim_s1_t_dis.step()\n",
    "            optim_s2_t_dis.step()\n",
    "\n",
    "            if (i+1) % log_interval == 0:\n",
    "                logging.warning('Step: %d, Gan epoch: %d, C1: %.2f, C2: %.2f, Dis1: %.2f, Dis2: %.2f, S1: %.2f, S2: %.2f, Selected: %s', \\\n",
    "                                step, gan_epoch, s1_cls_loss.data, s2_cls_loss.data, s1_t_dis_loss.data, \\\n",
    "                                s2_t_dis_loss.data, s1_t_confusion_loss.data, s2_t_confusion_loss.data, \\\n",
    "                                SELECTIVE_SOURCE)   \n",
    "   \n",
    "\n",
    "    # Both Classifier loss.\n",
    "#     s1_weight_loss += alpha_S1\n",
    "#     s2_weight_loss += alpha_S2\n",
    "    \n",
    "    s1_weight = s1_weight_loss / (s1_weight_loss + s2_weight_loss)\n",
    "    s2_weight = s2_weight_loss / (s1_weight_loss + s2_weight_loss)\n",
    "\n",
    "    s1_weight = s1_weight.cpu().data.numpy()\n",
    "    s2_weight = s2_weight.cpu().data.numpy()\n",
    "    \n",
    "    print(\"Step: {} #### Part2: Pseudo-label generation\".format(step))\n",
    "    extractor.eval()\n",
    "    classifier_A.eval()\n",
    "    classifier_B.eval()\n",
    "\n",
    "    pseudo_target_data = []\n",
    "    pseudo_target_label = []\n",
    "\n",
    "    \n",
    "\n",
    "    # Annotate from the target test dataset\n",
    "    for i, (t_sample, t_labels) in tqdm.tqdm(enumerate(target_loader)):\n",
    "        \n",
    "        pseudo_predicted = []\n",
    "        pseudo_original = []\n",
    "    \n",
    "        t_sample = Variable(t_sample.cuda(gpu_id))\n",
    "        t_feature = extractor(t_sample)\n",
    "\n",
    "        s1_cls = classifier_A(t_feature)\n",
    "        s2_cls = classifier_B(t_feature)\n",
    "\n",
    "        s1_cls = calculate_softmax(s1_cls)\n",
    "        s2_cls = calculate_softmax(s2_cls)\n",
    "        \n",
    "        s1_cls = s1_cls.data.cpu().numpy()\n",
    "        s2_cls = s2_cls.data.cpu().numpy()\n",
    "        \n",
    "        t_pred = s1_cls * s1_weight + s2_cls * s2_weight       \n",
    "        ids = t_pred.argmax(axis=1)\n",
    "        # ArgMax returns the indices of the max item\n",
    "        \n",
    "        \n",
    "        target_label = t_labels.data.cpu().numpy().astype(int)\n",
    "        \n",
    "        for j in range(ids.shape[0]):\n",
    "            if t_pred[j, ids[j]] >= threshold:\n",
    "                # Return input size: 9x1x128. Add an extra dimension at the beginning using np.newaxis\n",
    "                sample = t_sample[np.newaxis,j,:,:,:]\n",
    "                \n",
    "                pseudo_target_data.append(sample.cpu().numpy())\n",
    "                pseudo_target_label.append(ids[j])\n",
    "            \n",
    "                pseudo_predicted.append(ids[j])\n",
    "                pseudo_original.append(target_label[j])\n",
    "\n",
    "#     try:\n",
    "    print(\"Step: {} #### Part3:Train F and C using Pseudo-label\".format(step))\n",
    "\n",
    "    pseudo_target_data = np.concatenate( pseudo_target_data, axis=0 )\n",
    "    pseudo_target_label = np.array( pseudo_target_label )\n",
    "    logging.warning(\"Pseudo dataset shape: %s\", pseudo_target_data.shape)\n",
    "    logging.warning(\"Pseudo dataset label shape: %s\", pseudo_target_label.shape)\n",
    "\n",
    "    pseudo_target_loader = DataPreprocess.load(pseudo_target_data, pseudo_target_label)\n",
    "\n",
    "\n",
    "    for cls_epoch in range(cls_epoches):\n",
    "\n",
    "        extractor.train()\n",
    "        classifier_A.train()\n",
    "        classifier_B.train()\n",
    "        s1_loader, s2_loader, t_pse_loader = iter(source1_loader), iter(source2_loader), iter(pseudo_target_loader)    \n",
    "\n",
    "        # Use source datasets and pseudo target dataset\n",
    "        for i, (t_pse_sample, t_pse_labels) in tqdm.tqdm(enumerate(t_pse_loader)):\n",
    "            try:\n",
    "                s1_sample, s1_labels = s1_loader.next()\n",
    "            except StopIteration:\n",
    "                s1_loader = iter(source1_loader)\n",
    "                s1_sample, s1_labels = s1_loader.next()\n",
    "\n",
    "            try:\n",
    "                s2_sample, s2_labels = s2_loader.next()\n",
    "            except StopIteration:\n",
    "                s2_loader = iter(source2_loader)\n",
    "                s2_sample, s2_labels = s2_loader.next()\n",
    "\n",
    "            s1_sample, s1_labels = Variable(s1_sample.cuda(gpu_id)), Variable(s1_labels.cuda(gpu_id))\n",
    "            s2_sample, s2_labels = Variable(s2_sample.cuda(gpu_id)), Variable(s2_labels.cuda(gpu_id))\n",
    "\n",
    "            t_pse_sample =  np.swapaxes(t_pse_sample,1,3)\n",
    "            t_pse_sample, t_pse_labels = Variable(t_pse_sample.cuda(gpu_id)), Variable(t_pse_labels.cuda(gpu_id))\n",
    "            t_pse_labels = t_pse_labels.float()  \n",
    "\n",
    "            # Combine the source 1 and 2 images with pseudo leveled images\n",
    "            s1_t_sample = torch.cat((s1_sample, t_pse_sample), 0)\n",
    "            s1_t_labels = torch.cat((s1_labels, t_pse_labels), 0)\n",
    "            s2_t_sample = torch.cat((s2_sample, t_pse_sample), 0)\n",
    "            s2_t_labels = torch.cat((s2_labels, t_pse_labels), 0)\n",
    "\n",
    "            optim_extract.zero_grad()\n",
    "            optim_s1_cls.zero_grad()\n",
    "            optim_s2_cls.zero_grad()\n",
    "\n",
    "            s1_t_feature = extractor(s1_t_sample)\n",
    "            s2_t_feature = extractor(s2_t_sample)\n",
    "            s1_t_cls = classifier_A(s1_t_feature)\n",
    "            s2_t_cls = classifier_B(s2_t_feature)\n",
    "\n",
    "            s1_t_labels = s1_t_labels.long()\n",
    "            s2_t_labels = s2_t_labels.long()\n",
    "\n",
    "            s1_t_cls_loss = get_cls_loss(s1_t_cls, s1_t_labels)\n",
    "            s2_t_cls_loss = get_cls_loss(s2_t_cls, s2_t_labels)\n",
    "\n",
    "            # Will it update the extractor\n",
    "            torch.autograd.backward([s1_t_cls_loss, s2_t_cls_loss])\n",
    "\n",
    "            optim_s1_cls.step()\n",
    "            optim_s2_cls.step()\n",
    "            optim_extract.step()            \n",
    "#     except:      \n",
    "#         logging.warning(\"No array to concatenate\")\n",
    "    \n",
    "    print(\"Step: {} #### Part4: Evaluation\".format(step))\n",
    "    # This Evaluation can be moved out of the outer FOR Loop\n",
    "    extractor.eval()\n",
    "    classifier_A.eval()\n",
    "    classifier_B.eval()\n",
    "\n",
    "    prediction = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    correct = 0\n",
    "    for (sample, labels) in target_loader:\n",
    "        sample = Variable(sample.cuda(gpu_id))\n",
    "        sample_feature = extractor(sample)\n",
    "\n",
    "        s1_cls = classifier_A(sample_feature)\n",
    "        s2_cls = classifier_B(sample_feature)\n",
    "\n",
    "        s1_cls = s1_cls.data.cpu().numpy()\n",
    "        s2_cls = s2_cls.data.cpu().numpy()\n",
    "\n",
    "        # s1_weight and s2_weight should be generated from the discriminator\n",
    "        res = s1_cls * s1_weight + s2_cls * s2_weight\n",
    "\n",
    "        pred = res.argmax(axis=1)\n",
    "        labels = labels.numpy()\n",
    "        \n",
    "        prediction.extend(pred.tolist())\n",
    "        ground_truth.extend(labels.tolist())\n",
    "        \n",
    "        correct += np.equal(labels, pred).sum()\n",
    "    \n",
    "    current_accuracy = (correct * 1.0) / Total_Target_Sample\n",
    "    print(\"Current accuracy is: \", current_accuracy)\n",
    "    logging.warning(\"Current accuracy is: %s\", current_accuracy)\n",
    "\n",
    "    x_value.append(step)\n",
    "    y_value.append(current_accuracy)\n",
    "    \n",
    "    if current_accuracy >= max_correct:\n",
    "        max_correct = current_accuracy\n",
    "        max_step = step\n",
    "        max_epoch = gan_epoch\n",
    "#         torch.save(extractor.state_dict(), os.path.join(snapshot, \"extractor_\" + str(max_step) + \"_\" + str(max_epoch) + \".pth\"))\n",
    "#         torch.save(classifier_A.state_dict(), os.path.join(snapshot, \"classifier_A_\" + str(max_step) + \"_\" + str(max_epoch) + \".pth\"))\n",
    "#         torch.save(classifier_B.state_dict(), os.path.join(snapshot, \"classifier_B_\" + str(max_step) + \"_\" + str(max_epoch) + \".pth\"))\n",
    "\n",
    "    \n",
    "    if step == steps-1:\n",
    "        print(\"Printing the confusion matrix\")\n",
    "\n",
    "        plot_cm = confusion_matrix(ground_truth, prediction)\n",
    "        print(plot_cm)\n",
    "        plot_confusion_matrix(cm = plot_cm, \n",
    "                   target_names = ['Ascending Strairs','Sitting','Cycling','Walking'],\n",
    "                     cmap = None,\n",
    "                     normalize    = False,\n",
    "                     title        = \"Confusion Matrix\")\n",
    "        \n",
    "        print(precision_recall_fscore_support(ground_truth, prediction, average='macro'))\n",
    "    \n",
    "# print(\"--- %s seconds ---\", (time.time() - start_time)/60000)\n",
    "logging.warning(\"Best accuracy is: %s\", max_correct)\n",
    "logging.warning(\"Best accuracy at iteration: %s\", max_step)\n",
    "\n",
    "training_plot(x_value, y_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax()\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max([2.13040713e-25,9.37593388e-40,2.83372893e-21,4.75788653e-01,5.24210751e-01,6.50217298e-17,5.74490457e-07])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append(\"1\")\n",
    "a.append(\"2\")\n",
    "a.append(\"3\")\n",
    "a.append(\"4\")\n",
    "a.append(\"5\")\n",
    "a.append(\"6\")\n",
    "a.append(\"7\")\n",
    "a.append(\"8\")\n",
    "a.append(\"9\")\n",
    "a.append(\"10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = [0, 0, 2, 0, 0]\n",
    "# y_pred = [3, 3, 3, 3, 3]\n",
    "# confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upto = int(len(a)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0:upto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
